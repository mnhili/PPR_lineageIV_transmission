{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:06:19.950037Z",
     "start_time": "2024-07-16T11:05:49.791216Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pymc.sampling_jax\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:06:19.965329Z",
     "start_time": "2024-07-16T11:06:19.953067Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_mean_roc(y_true, posterior_samples, title='Mean ROC curve with 95% CI'):\n",
    "    fpr_grid = np.linspace(0, 1, 64)\n",
    "    tpr_interpolated = []\n",
    "    aucs = []\n",
    "    \n",
    "    \n",
    "    for i in range(posterior_samples.shape[1]):\n",
    "        y_scores = posterior_samples[i]\n",
    "        fpr, tpr, _ = roc_curve(y, y_scores)\n",
    "        tpr_interpolated.append(np.interp(fpr_grid, fpr, tpr))\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "    \n",
    "    # Convertir en array numpy pour faciliter les calculs\n",
    "    tpr_interpolated = np.array(tpr_interpolated)\n",
    "    \n",
    "    # Calculer la TPR moyenne et son intervalle de confiance à 95%\n",
    "    mean_tpr = tpr_interpolated.mean(axis=0)\n",
    "    std_tpr = tpr_interpolated.std(axis=0)\n",
    "    ci_lower = np.percentile(tpr_interpolated, 2.5, axis=0)\n",
    "    ci_upper = np.percentile(tpr_interpolated, 97.5, axis=0)\n",
    "    \n",
    "    # Calculer la moyenne des AUC\n",
    "    mean_auc = np.mean(aucs)\n",
    "    lower_auc = np.percentile(aucs, 2.5)\n",
    "    upper_auc = np.percentile(aucs, 97.5)\n",
    "\n",
    "    # Create the title with the mean AUC and 95% CI\n",
    "    title = f'Mean ROC curve with 95% CI (AUC = {mean_auc:.2f}, 95% CI: {lower_auc:.2f} - {upper_auc:.2f})'\n",
    "\n",
    "    \n",
    "    # Tracer la courbe ROC moyenne avec les intervalles de confiance\n",
    "    plt.plot(fpr_grid, mean_tpr, color='blue', label='Mean ROC')\n",
    "    plt.fill_between(fpr_grid, ci_lower, ci_upper, color='blue', alpha=0.2, label='95% CI')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:06:19.980632Z",
     "start_time": "2024-07-16T11:06:19.968370Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_mean_f1(y_true, posterior_samples, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calcule et affiche la moyenne des F1 scores à partir des échantillons postérieurs.\n",
    "    \n",
    "    :param y_true: np.array, vecteur de labels binaires de taille (n_samples,)\n",
    "    :param posterior_samples: np.array, matrice de taille (n_samples, n_estimations)\n",
    "    :param threshold: float, seuil pour convertir les scores en labels binaires\n",
    "    :return: float, moyenne des F1 scores\n",
    "    \"\"\"\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(posterior_samples.shape[1]):\n",
    "        y_scores = posterior_samples[i]\n",
    "        y_pred = (y_scores >= threshold).astype(int)\n",
    "        f1_scores.append(f1_score(y_true, y_pred))\n",
    "\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    print(f'Mean F1 Score: {mean_f1:.2f}')\n",
    "    return mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:06:19.995889Z",
     "start_time": "2024-07-16T11:06:19.982660Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_mean_confusion_matrix(y_true, posterior_samples, threshold=0.5): \n",
    "    \"\"\"\n",
    "    Calcule et affiche la moyenne des matrices de confusion à partir des échantillons postérieurs.\n",
    "    \n",
    "    :param y_true: np.array, vecteur de labels binaires de taille (n_samples,) \n",
    "    :param posterior_samples: np.array, matrice de taille (n_samples, n_estimations)\n",
    "    :param threshold: float, seuil pour convertir les scores en labels binaires\n",
    "    :return: np.array, matrice de confusion moyenne \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    confusion_matrices = [] \n",
    "\n",
    "    for i in range(posterior_samples.shape[1]): \n",
    "        y_scores = posterior_samples[i] \n",
    "        y_pred = (y_scores >= threshold).astype(int)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        confusion_matrices.append(cm) \n",
    "\n",
    "    mean_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "    print(f'Mean Confusion Matrix:\\n{mean_confusion_matrix}')\n",
    "    return mean_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T13:52:49.099959Z",
     "start_time": "2024-07-16T13:52:49.086668Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_information_criteria(trace, model, y):\n",
    "    \"\"\"\n",
    "    Calculate AIC, BIC, and WAIC for a PyMC model using arviz.InferenceData.\n",
    "    \n",
    "    Parameters:\n",
    "    trace (arviz.InferenceData): Posterior samples from the model.\n",
    "    model (pymc.Model): The PyMC model object.\n",
    "    y (array-like): Observed data.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing AIC, BIC, and WAIC values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if log_likelihood already exists in trace\n",
    "    if 'log_likelihood' not in trace.groups():\n",
    "        # Compute log-likelihood if not already computed\n",
    "        pm.compute_log_likelihood(trace, model=model)\n",
    "    \n",
    "    # Extract log-likelihood\n",
    "    log_likelihood = trace.log_likelihood['y_obs'].values\n",
    "    \n",
    "    # Check for and remove any infinite values\n",
    "    finite_log_likelihood = log_likelihood[np.isfinite(log_likelihood)]\n",
    "    \n",
    "    if len(finite_log_likelihood) == 0:\n",
    "        logging.error(\"All log-likelihood values are non-finite.\")\n",
    "        return {'AIC': np.nan, 'BIC': np.nan, 'WAIC': np.nan}\n",
    "    \n",
    "    if len(finite_log_likelihood) < len(log_likelihood):\n",
    "        logging.warning(f\"Removed {len(log_likelihood) - len(finite_log_likelihood)} non-finite log-likelihood values.\")\n",
    "    \n",
    "    parameter_names = [var for var in trace.posterior.data_vars if not var.endswith('_') and var != 'p_i']\n",
    "    \n",
    "    # Number of parameters\n",
    "    k = len(parameter_names)\n",
    "    \n",
    "    # Number of data points\n",
    "    n = len(y)\n",
    "    \n",
    "    # Compute mean log-likelihood\n",
    "    mean_log_likelihood = np.mean(finite_log_likelihood)\n",
    "    \n",
    "    # Compute AIC\n",
    "    aic = 2 * k - 2 * mean_log_likelihood\n",
    "    \n",
    "    # Compute BIC\n",
    "    bic = k * np.log(n) - 2 * mean_log_likelihood\n",
    "    \n",
    "    # Compute WAIC\n",
    "    try:\n",
    "        waic = az.waic(trace)\n",
    "        waic_value = waic\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error computing WAIC: {str(e)}\")\n",
    "        waic_value = np.nan\n",
    "        \n",
    "    return {\n",
    "        'AIC': aic,\n",
    "        'BIC': bic,\n",
    "        'WAIC': waic_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:06:20.041912Z",
     "start_time": "2024-07-16T11:06:20.013301Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in data and display first 5 lines\n",
    "data = pd.read_csv(\"/mnt/d/Last_attempt/proximity_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:06:20.057207Z",
     "start_time": "2024-07-16T11:06:20.043958Z"
    }
   },
   "outputs": [],
   "source": [
    "y = data[\"infected\"].to_numpy()\n",
    "t0 = data['time_between_0.05_and_0.5m'].to_numpy()\n",
    "t1 = data['time_between_0.5_and_1m'].to_numpy()\n",
    "t2 = data['time_between_1_and_2m'].to_numpy()\n",
    "t3 = data['time_above_2m'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. model 1:\n",
    "\n",
    "$$p_i = 1 - (1-p)^{t_0} \\cdot (1-\\alpha_{1} p)^{t_1} \\cdot (1-\\alpha_{2} p)^{t_2} \\cdot (1-\\alpha_{3} p)^{t_3} \\qquad where \\qquad \\alpha_3 < \\alpha_2 < \\alpha_1, \\quad \\alpha_1 < 1$$\n",
    "\n",
    "2. model 2:\n",
    "\n",
    "$$p_i = 1 - (1-p)^{t_0} \\cdot (1-\\alpha_{1} p)^{t_1}  \\qquad where \\qquad  \\alpha_1 < 1$$\n",
    "\n",
    "3. model 3:\n",
    "\n",
    "$$p_i = 1 - (1- p)^{t_2} \\cdot (1-\\alpha_{1} p)^{t_3} \\qquad where \\qquad  \\alpha_1 < 1$$\n",
    "\n",
    "4. model 4:\n",
    "\n",
    "$$p_i = 1 - (1- p)^{t_1} \\cdot (1-\\alpha_{1} p)^{t_2} \\cdot (1-\\alpha_{2} p)^{t_3} \\qquad where \\qquad  \\alpha_2 < \\alpha_1 < 1  $$\n",
    "\n",
    "5. model 5:\n",
    "$$p_i = 1 - (1-p)^{t_0} \\cdot (1-\\alpha_{1} p)^{t_1} \\cdot (1-\\alpha_{2} p)^{t_2}  \\qquad where \\qquad  \\alpha_2 < \\alpha_1 < 1$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T13:31:59.886993Z",
     "start_time": "2024-07-16T13:31:39.868387Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model1:\n",
    "    # Priors\n",
    "    p = pm.Beta('p', 1, 1)\n",
    "\n",
    "    alpha_1 = pm.Uniform('alpha_1', 0, 1)\n",
    "    alpha_2 = pm.Uniform('alpha_2', 0, 1)\n",
    "    alpha_3 = pm.Uniform('alpha_3', 0, 1)\n",
    "\n",
    "\n",
    "    p_i = 1 - (1 - p)**t0 * (1 - alpha_1 * p)**t1 * (1 - alpha_1* alpha_2 * p)**t2 * (1 - alpha_1 * alpha_2* alpha_3 * p)**t3\n",
    "\n",
    "\n",
    "    alpha_12 = pm.Deterministic('alpha_12', alpha_1* alpha_2)\n",
    "\n",
    "    alpha_123 = pm.Deterministic('alpha_123',alpha_1 * alpha_2* alpha_3)\n",
    "\n",
    "    \n",
    "    p_i = pm.Deterministic('p_i', p_i)\n",
    "\n",
    "    # Ind = pm.Deterministic('Ind', int((alpha_1 > alpha_2) and (alpha_2 > alpha_3)))\n",
    "\n",
    "    # Likelihood\n",
    "    y_true = pm.Bernoulli('y_obs', p=p_i, observed=y)\n",
    "\n",
    "\n",
    "    init = {'p': 0.001}\n",
    "\n",
    "with model1:\n",
    "    trace1 = pm.sampling.jax.sample_blackjax_nuts(draws=10000, tune=1000, chains=10, target_accept=0.96, initvals=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:19:04.450147Z",
     "start_time": "2024-07-16T11:18:55.364849Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with pm.Model() as model2:\n",
    "    # Priors\n",
    "    p = pm.Beta('p', 1, 1)\n",
    "    alpha_1 = pm.Uniform('alpha_1', 0, 1)    \n",
    "    \n",
    "    p_i = 1 - (1 - p)**t0 * (1 - alpha_1 * p)**t1 \n",
    "    p_i = pm.Deterministic('p_i', p_i)\n",
    "\n",
    "    # Likelihood\n",
    "    y_true = pm.Bernoulli('y_obs', p=p_i, observed=y)\n",
    "\n",
    "    init = {'p': 0.001}\n",
    "\n",
    "with model2:\n",
    "    trace2 = pm.sampling.jax.sample_blackjax_nuts(draws=10000, tune=1000, chains=10, target_accept=0.95, initvals=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:20:06.419139Z",
     "start_time": "2024-07-16T11:19:55.791974Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model3:\n",
    "    # Priors\n",
    "    p = pm.Beta('p', 1, 1)\n",
    "    # alpha_2 = pm.Uniform('alpha_2', 0, 1)\n",
    "    alpha_3 = pm.Uniform('alpha_3', 0, 1)    \n",
    "    p_i = 1 - (1 - p)**t2 * (1 - alpha_3*p)**t3\n",
    "    p_i = pm.Deterministic('p_i', p_i)\n",
    "\n",
    "    # Likelihood\n",
    "    y_true = pm.Bernoulli('y_obs', p=p_i, observed=y)\n",
    "\n",
    "    init = {'p': 0.001}\n",
    "\n",
    "with model3:\n",
    "    trace3 = pm.sampling.jax.sample_blackjax_nuts(draws=10000, tune=1000, chains=10, target_accept=0.95, initvals=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:20:21.029975Z",
     "start_time": "2024-07-16T11:20:06.419139Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with pm.Model() as model4:\n",
    "    # Priors\n",
    "\n",
    "    p = pm.Beta('p', 1, 1)\n",
    "    alpha_2 = pm.Uniform('alpha_2', 0, 1) \n",
    "    alpha_3 = pm.Uniform('alpha_3', 0, 1) \n",
    "\n",
    "    p_i = 1 - (1 - p)**t1 * (1 - alpha_2 * p)**t2 * (1 - alpha_3 * p)**t3\n",
    "\n",
    "    \n",
    "    p_i = pm.Deterministic('p_i', p_i)\n",
    "\n",
    "    # Likelihood\n",
    "    y_true = pm.Bernoulli('y_obs', p=p_i, observed=y)\n",
    "\n",
    "    init = {'p': 0.001}\n",
    "\n",
    "with model4:\n",
    "    trace4 = pm.sampling.jax.sample_blackjax_nuts(draws=10000, tune=1000, chains=10, target_accept=0.95, initvals=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model5:\n",
    "    # Priors\n",
    "    p = pm.Beta('p', 1, 1)\n",
    "\n",
    "    alpha_1 = pm.Uniform('alpha_1', 0, 1)\n",
    "    alpha_2 = pm.Uniform('alpha_2', 0, 1)\n",
    "\n",
    "    p_i = 1 - (1 - p)**t0 * (1 - alpha_1 * p)**t1 * (1 - alpha_1* alpha_2 * p)**t2 \n",
    "\n",
    "    alpha_12 = pm.Deterministic('alpha_12', alpha_1* alpha_2)\n",
    "    \n",
    "    p_i = pm.Deterministic('p_i', p_i)\n",
    "\n",
    "\n",
    "    # Likelihood\n",
    "    y_true = pm.Bernoulli('y_obs', p=p_i, observed=y)\n",
    "\n",
    "    init = {'p': 0.001}\n",
    "\n",
    "with model5:\n",
    "    trace5 = pm.sampling.jax.sample_blackjax_nuts(draws=10000, tune=1000, chains=10, target_accept=0.96, initvals=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T13:36:16.204356Z",
     "start_time": "2024-07-16T13:36:16.188414Z"
    }
   },
   "outputs": [],
   "source": [
    "# samples1 = trace1.posterior.stack(sample=(\"chain\", \"draw\"))\n",
    "# samples2 = trace2.posterior.stack(sample=(\"chain\", \"draw\"))\n",
    "# samples3 = trace3.posterior.stack(sample=(\"chain\", \"draw\"))\n",
    "# samples4 = trace4.posterior.stack(sample=(\"chain\", \"draw\"))\n",
    "samples5 = trace5.posterior.stack(sample=(\"chain\", \"draw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T13:36:17.218107Z",
     "start_time": "2024-07-16T13:36:17.206610Z"
    }
   },
   "outputs": [],
   "source": [
    "# p_ind1 = pd.DataFrame(samples1['p_i'].values)\n",
    "# p_ind2 = pd.DataFrame(samples2['p_i'].values)\n",
    "# p_ind3 = pd.DataFrame(samples3['p_i'].values)\n",
    "# p_ind4 = pd.DataFrame(samples4['p_i'].values)\n",
    "p_ind5 = pd.DataFrame(samples5['p_i'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace5, hdi_prob=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace5, round_to=4, hdi_prob=.95);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace2, round_to=4, hdi_prob=.95);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace3, round_to=4, hdi_prob=.95);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace4, round_to=4, hdi_prob=.95);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_model1 = plot_mean_roc(y, p_ind1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_model2 = plot_mean_roc(y, p_ind2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_model3 = plot_mean_roc(y, p_ind3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_model4 = plot_mean_roc(y, p_ind4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_model5 = plot_mean_roc(y, p_ind5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_model1 = calculate_mean_confusion_matrix(y, p_ind1, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_model2 = calculate_mean_confusion_matrix(y, p_ind2, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_model3 = calculate_mean_confusion_matrix(y, p_ind3, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_model4 = calculate_mean_confusion_matrix(y, p_ind4, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cm_model5 = calculate_mean_confusion_matrix(y, p_ind5, threshold=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Define the labels for the confusion matrix\n",
    "labels = ['Not Infected', 'Infected']\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_model5, annot=True, fmt='.0f', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison: AIC & BIC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T13:36:36.384353Z",
     "start_time": "2024-07-16T13:36:29.261613Z"
    }
   },
   "outputs": [],
   "source": [
    "results1 = calculate_information_criteria(trace1, model1, y)\n",
    "\n",
    "print(f\"AIC: {results1['AIC']}\")\n",
    "print(f\"BIC: {results1['BIC']}\")\n",
    "print(f\"WAIC: {results1['WAIC']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:22:34.948607Z",
     "start_time": "2024-07-16T11:22:34.901706Z"
    }
   },
   "outputs": [],
   "source": [
    "# samples1 = trace1.posterior.stack(sample=(\"chain\", \"draw\"))\n",
    "\n",
    "# alpha1_samples1 = samples1['alpha_1'].values\n",
    "\n",
    "# min(alpha1_samples1), max(alpha1_samples1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:25:25.985481Z",
     "start_time": "2024-07-16T11:25:21.168018Z"
    }
   },
   "outputs": [],
   "source": [
    "results2 = calculate_information_criteria(trace2, model2, y)\n",
    "\n",
    "print(f\"AIC: {results2['AIC']}\")\n",
    "print(f\"BIC: {results2['BIC']}\")\n",
    "print(f\"WAIC: {results2['WAIC']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:25:47.702764Z",
     "start_time": "2024-07-16T11:25:43.003387Z"
    }
   },
   "outputs": [],
   "source": [
    "results3 = calculate_information_criteria(trace3, model3, y)\n",
    "\n",
    "print(f\"AIC: {results3['AIC']}\")\n",
    "print(f\"BIC: {results3['BIC']}\")\n",
    "print(f\"WAIC: {results3['WAIC']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:25:58.216153Z",
     "start_time": "2024-07-16T11:25:52.102998Z"
    }
   },
   "outputs": [],
   "source": [
    "results4 = calculate_information_criteria(trace4, model4, y)\n",
    "\n",
    "print(f\"AIC: {results4['AIC']}\")\n",
    "print(f\"BIC: {results4['BIC']}\")\n",
    "print(f\"WAIC: {results4['WAIC']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results5 = calculate_information_criteria(trace5, model5, y)\n",
    "\n",
    "print(f\"AIC: {results5['AIC']}\")\n",
    "print(f\"BIC: {results5['BIC']}\")\n",
    "print(f\"WAIC: {results5['WAIC']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison: Widely Applicable Information Criterion (WAIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:55:38.787179Z",
     "start_time": "2024-07-16T12:55:38.771521Z"
    }
   },
   "outputs": [],
   "source": [
    "log_likelihood = trace2.log_likelihood\n",
    "print(log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:55:43.107866Z",
     "start_time": "2024-07-16T12:55:43.060914Z"
    }
   },
   "outputs": [],
   "source": [
    "log_likelihood_data = trace2['log_likelihood']\n",
    "print(np.isnan(log_likelihood_data).sum(), \"\\n\\n\")\n",
    "print(np.isinf(log_likelihood_data).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:56:17.694584Z",
     "start_time": "2024-07-16T12:56:17.663310Z"
    }
   },
   "outputs": [],
   "source": [
    "inf_indices = np.isinf(log_likelihood_data['y_obs']).values\n",
    "print(\"Indices des valeurs infinies :\", np.where(inf_indices)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:56:24.577338Z",
     "start_time": "2024-07-16T12:56:24.361880Z"
    }
   },
   "outputs": [],
   "source": [
    "waic1 = pm.waic(trace1, model1)\n",
    "waic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:56:26.395077Z",
     "start_time": "2024-07-16T12:56:26.162354Z"
    }
   },
   "outputs": [],
   "source": [
    "waic2 = pm.waic(trace2, model2)\n",
    "waic2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:56:28.011407Z",
     "start_time": "2024-07-16T12:56:27.796962Z"
    }
   },
   "outputs": [],
   "source": [
    "waic3 = pm.waic(trace3, model3)\n",
    "waic3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:56:29.763341Z",
     "start_time": "2024-07-16T12:56:29.561785Z"
    }
   },
   "outputs": [],
   "source": [
    "waic4 = pm.waic(trace4, model4)\n",
    "waic4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison: Pareto-smoothed importance sampling leave-one-out cross-validation (PSIS-LOO-CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:56:46.159296Z",
     "start_time": "2024-07-16T12:56:39.608919Z"
    }
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"model1\": trace1,\n",
    "    \"model2\": trace2,\n",
    "    \"model3\": trace3,\n",
    "    \"model4\": trace4,\n",
    "    \"model5\": trace5\n",
    "}\n",
    "model_compare_default = az.compare(models)\n",
    "model_compare_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:56:50.960768Z",
     "start_time": "2024-07-16T12:56:50.562444Z"
    }
   },
   "outputs": [],
   "source": [
    "az.plot_compare(model_compare_default, insample_dev=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:56:56.559533Z",
     "start_time": "2024-07-16T12:56:55.494193Z"
    }
   },
   "outputs": [],
   "source": [
    "model_compare_waic = az.compare(models, ic='waic', method='BB-pseudo-BMA', b_samples=1000)\n",
    "model_compare_waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:57:04.213906Z",
     "start_time": "2024-07-16T12:56:58.079002Z"
    }
   },
   "outputs": [],
   "source": [
    "model_compare_loo = az.compare(models, ic='loo', method='BB-pseudo-BMA', b_samples=1000)\n",
    "model_compare_loo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report: F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_model1 = calculate_mean_f1(y, p_ind1, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_model2 = calculate_mean_f1(y, p_ind2, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_model3 = calculate_mean_f1(y, p_ind3, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_model4 = calculate_mean_f1(y, p_ind4, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models' traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('trace_model5.pkl', 'wb') as f:\n",
    "#     pickle.dump(trace5, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('trace_model1.pkl', 'wb') as f:\n",
    "#     pickle.dump(trace1, f)\n",
    "\n",
    "# with open('trace_model2.pkl', 'wb') as f:\n",
    "#     pickle.dump(trace2, f)\n",
    "\n",
    "# with open('trace_model3.pkl', 'wb') as f:\n",
    "#     pickle.dump(trace3, f)\n",
    "\n",
    "# with open('trace_model4.pkl', 'wb') as f:\n",
    "#     pickle.dump(trace4, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
