{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pymc.sampling_jax\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_roc(y_true, posterior_samples, title='Mean ROC curve with 95% CI'):\n",
    "    fpr_grid = np.linspace(0, 1, 64)\n",
    "    tpr_interpolated = []\n",
    "    aucs = []\n",
    "    \n",
    "    \n",
    "    for i in range(posterior_samples.shape[1]):\n",
    "        y_scores = posterior_samples[i]\n",
    "        fpr, tpr, _ = roc_curve(y, y_scores)\n",
    "        tpr_interpolated.append(np.interp(fpr_grid, fpr, tpr))\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "    \n",
    "    # Convertir en array numpy pour faciliter les calculs\n",
    "    tpr_interpolated = np.array(tpr_interpolated)\n",
    "    \n",
    "    # Calculer la TPR moyenne et son intervalle de confiance à 95%\n",
    "    mean_tpr = tpr_interpolated.mean(axis=0)\n",
    "    std_tpr = tpr_interpolated.std(axis=0)\n",
    "    ci_lower = np.percentile(tpr_interpolated, 2.5, axis=0)\n",
    "    ci_upper = np.percentile(tpr_interpolated, 97.5, axis=0)\n",
    "    \n",
    "    # Calculer la moyenne des AUC\n",
    "    mean_auc = np.mean(aucs)\n",
    "    lower_auc = np.percentile(aucs, 2.5)\n",
    "    upper_auc = np.percentile(aucs, 97.5)\n",
    "\n",
    "    # Create the title with the mean AUC and 95% CI\n",
    "    title = f'Mean ROC curve with 95% CI (AUC = {mean_auc:.2f}, 95% CI: {lower_auc:.2f} - {upper_auc:.2f})'\n",
    "\n",
    "    \n",
    "    # Tracer la courbe ROC moyenne avec les intervalles de confiance\n",
    "    plt.plot(fpr_grid, mean_tpr, color='blue', label='Mean ROC')\n",
    "    plt.fill_between(fpr_grid, ci_lower, ci_upper, color='blue', alpha=0.2, label='95% CI')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_f1(y_true, posterior_samples, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calcule et affiche la moyenne des F1 scores à partir des échantillons postérieurs.\n",
    "    \n",
    "    :param y_true: np.array, vecteur de labels binaires de taille (n_samples,)\n",
    "    :param posterior_samples: np.array, matrice de taille (n_samples, n_estimations)\n",
    "    :param threshold: float, seuil pour convertir les scores en labels binaires\n",
    "    :return: float, moyenne des F1 scores\n",
    "    \"\"\"\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(posterior_samples.shape[1]):\n",
    "        y_scores = posterior_samples[i]\n",
    "        y_pred = (y_scores >= threshold).astype(int)\n",
    "        f1_scores.append(f1_score(y_true, y_pred))\n",
    "\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    print(f'Mean F1 Score: {mean_f1:.2f}')\n",
    "    return mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_confusion_matrix(y_true, posterior_samples, threshold=0.5): \n",
    "    \"\"\"\n",
    "    Calcule et affiche la moyenne des matrices de confusion à partir des échantillons postérieurs.\n",
    "    \n",
    "    :param y_true: np.array, vecteur de labels binaires de taille (n_samples,) \n",
    "    :param posterior_samples: np.array, matrice de taille (n_samples, n_estimations)\n",
    "    :param threshold: float, seuil pour convertir les scores en labels binaires\n",
    "    :return: np.array, matrice de confusion moyenne \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    confusion_matrices = [] \n",
    "\n",
    "    for i in range(posterior_samples.shape[1]): \n",
    "        y_scores = posterior_samples[i] \n",
    "        y_pred = (y_scores >= threshold).astype(int)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        confusion_matrices.append(cm) \n",
    "\n",
    "    mean_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "    print(f'Mean Confusion Matrix:\\n{mean_confusion_matrix}')\n",
    "    return mean_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_criteria(trace, model, y):\n",
    "    \"\"\"\n",
    "    Calculate AIC, BIC, and WAIC for a PyMC model using arviz.InferenceData.\n",
    "    \n",
    "    Parameters:\n",
    "    trace (arviz.InferenceData): Posterior samples from the model.\n",
    "    model (pymc.Model): The PyMC model object.\n",
    "    y (array-like): Observed data.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing AIC, BIC, and WAIC values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if log_likelihood already exists in trace\n",
    "    if 'log_likelihood' not in trace.groups():\n",
    "        # Compute log-likelihood if not already computed\n",
    "        pm.compute_log_likelihood(trace, model=model)\n",
    "    \n",
    "    # Extract log-likelihood\n",
    "    log_likelihood = trace.log_likelihood['y_obs'].values\n",
    "    \n",
    "    # Check for and remove any infinite values\n",
    "    finite_log_likelihood = log_likelihood[np.isfinite(log_likelihood)]\n",
    "    \n",
    "    if len(finite_log_likelihood) == 0:\n",
    "        logging.error(\"All log-likelihood values are non-finite.\")\n",
    "        return {'AIC': np.nan, 'BIC': np.nan, 'WAIC': np.nan}\n",
    "    \n",
    "    if len(finite_log_likelihood) < len(log_likelihood):\n",
    "        logging.warning(f\"Removed {len(log_likelihood) - len(finite_log_likelihood)} non-finite log-likelihood values.\")\n",
    "    \n",
    "    parameter_names = [var for var in trace.posterior.data_vars if not var.endswith('_') and var != 'p_i']\n",
    "    \n",
    "    # Number of parameters\n",
    "    k = len(parameter_names)\n",
    "    \n",
    "    # Number of data points\n",
    "    n = len(y)\n",
    "    \n",
    "    # Compute mean log-likelihood\n",
    "    mean_log_likelihood = np.mean(finite_log_likelihood)\n",
    "    \n",
    "    # Compute AIC\n",
    "    aic = 2 * k - 2 * mean_log_likelihood\n",
    "    \n",
    "    # Compute BIC\n",
    "    bic = k * np.log(n) - 2 * mean_log_likelihood\n",
    "    \n",
    "    # Compute WAIC\n",
    "    try:\n",
    "        waic = az.waic(trace)\n",
    "        waic_value = waic\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error computing WAIC: {str(e)}\")\n",
    "        waic_value = np.nan\n",
    "    \n",
    "    return {\n",
    "        'AIC': aic,\n",
    "        'BIC': bic,\n",
    "        'WAIC': waic_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>duration</th>\n",
       "      <th>seeder</th>\n",
       "      <th>Cap2</th>\n",
       "      <th>time_between_0.05_and_0.5m</th>\n",
       "      <th>time_between_0.5_and_1m</th>\n",
       "      <th>time_between_1_and_2m</th>\n",
       "      <th>time_above_2m</th>\n",
       "      <th>infected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>436</td>\n",
       "      <td>100</td>\n",
       "      <td>2.783333</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>23.483333</td>\n",
       "      <td>25.850000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>436</td>\n",
       "      <td>116</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>20.983333</td>\n",
       "      <td>23.216667</td>\n",
       "      <td>13.916667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>436</td>\n",
       "      <td>255</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>8.416667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>436</td>\n",
       "      <td>449</td>\n",
       "      <td>17.016667</td>\n",
       "      <td>20.733333</td>\n",
       "      <td>15.933333</td>\n",
       "      <td>9.050000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>436</td>\n",
       "      <td>3008</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>51.816667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment  duration  seeder  Cap2  time_between_0.05_and_0.5m  \\\n",
       "0           1         1     436   100                    2.783333   \n",
       "1           1         1     436   116                    4.500000   \n",
       "2           1         1     436   255                    6.200000   \n",
       "3           1         1     436   449                   17.016667   \n",
       "4           1         1     436  3008                    0.183333   \n",
       "\n",
       "   time_between_0.5_and_1m  time_between_1_and_2m  time_above_2m  infected  \n",
       "0                10.600000              23.483333      25.850000         0  \n",
       "1                20.983333              23.216667      13.916667         0  \n",
       "2                20.900000              27.200000       8.416667         0  \n",
       "3                20.733333              15.933333       9.050000         0  \n",
       "4                 1.033333               9.700000      51.816667         0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data and display first 5 lines\n",
    "data = pd.read_csv(\"D:/Last_attempt/proximity_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"infected\"].to_numpy()\n",
    "t0 = data['time_between_0.05_and_0.5m'].to_numpy()\n",
    "t1 = data['time_between_0.5_and_1m'].to_numpy()\n",
    "t2 = data['time_between_1_and_2m'].to_numpy()\n",
    "t3 = data['time_above_2m'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. model 1:\n",
    "\n",
    "$$p_i = 1 - (1-p)^{t_0} \\cdot (1-\\alpha_{1} p)^{t_1} \\cdot (1-\\alpha_{2} p)^{t_2} \\cdot (1-\\alpha_{3} p)^{t_3} \\qquad where \\qquad \\alpha_3 < \\alpha_2 < \\alpha_1, \\quad \\alpha_1 < 1$$\n",
    "\n",
    "2. model 2:\n",
    "\n",
    "$$p_i = 1 - (1-p)^{t_0} \\cdot (1-\\alpha_{1} p)^{t_1}  \\qquad where \\qquad \\alpha_2 < \\alpha_1, \\quad \\alpha_1 < 1$$\n",
    "\n",
    "3. model 3:\n",
    "\n",
    "$$p_i = 1 - (1-\\alpha_{2} p)^{t_2} \\cdot (1-\\alpha_{3} p)^{t_3} \\qquad where \\qquad \\alpha_3 < \\alpha_2  \\quad \\alpha_2 < 1$$\n",
    "\n",
    "4. model 4:\n",
    "\n",
    "$$p_i = 1 - (1-\\alpha_{1} p)^{t_1} \\cdot (1-\\alpha_{2} p)^{t_2} \\cdot (1-\\alpha_{3} p)^{t_3} \\qquad where \\qquad \\alpha_3 < \\alpha_2 < \\alpha_1, \\quad \\alpha_1 < 1$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with pm.Model() as model1:\n",
    "    # Priors\n",
    "    p = pm.Beta('p', 1, 1)\n",
    "    # alpha_1 = pm.Normal('alpha_1', 0.5, 0.1)\n",
    "\n",
    "    alpha_1 = pm.TruncatedNormal('alpha_1', mu=0.5, sigma=0.1, lower=0.057, upper=1)\n",
    "    alpha_2 = pm.Normal('alpha_2', 0.25, 0.1)\n",
    "    alpha_3 = pm.Normal('alpha_3', 0.125, 0.05)\n",
    "\n",
    "    p_i = 1 - (1 - p)**t0 * (1 - alpha_1 * p)**t1 * (1 - alpha_2 * p)**t2 * (1 - alpha_3 * p)**t3\n",
    "\n",
    "    \n",
    "    p_i = pm.Deterministic('p_i', p_i)\n",
    "\n",
    "    # Likelihood\n",
    "    y_true = pm.Bernoulli('y_obs', p=p_i, observed=y)\n",
    "\n",
    "    init = {'p': 0.001}\n",
    "\n",
    "with model1:\n",
    "    trace1 = pm.sampling.jax.sample_blackjax_nuts(draws=10000, tune=1000, chains=10, target_accept=0.95, initvals=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with pm.Model() as model2:\n",
    "    # Priors\n",
    "    p = pm.Beta('p', 1, 1)\n",
    "    alpha_1 = pm.Normal('alpha_1', 0.5, 0.1)    \n",
    "    \n",
    "    p_i = 1 - (1 - p)**t0 * (1 - alpha_1 * p)**t1 \n",
    "    p_i = pm.Deterministic('p_i', p_i)\n",
    "\n",
    "    # Likelihood\n",
    "    y_true = pm.Bernoulli('y_obs', p=p_i, observed=y)\n",
    "\n",
    "    init = {'p': 0.001}\n",
    "\n",
    "with model2:\n",
    "    trace2 = pm.sampling.jax.sample_blackjax_nuts(draws=10000, tune=1000, chains=10, target_accept=0.95, initvals=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with pm.Model() as model3:\n",
    "    # Priors\n",
    "    p = pm.Beta('p', 1, 1)\n",
    "    # alpha_2 = pm.Uniform('alpha_2', 0, 1)\n",
    "    alpha_3 = pm.Normal('alpha_3', 0.5, 0.1)    \n",
    "    p_i = 1 - (1 - p)**t2 * (1 - alpha_3*p)**t3\n",
    "    p_i = pm.Deterministic('p_i', p_i)\n",
    "\n",
    "    # Likelihood\n",
    "    y_true = pm.Bernoulli('y_obs', p=p_i, observed=y)\n",
    "\n",
    "    init = {'p': 0.001}\n",
    "\n",
    "with model3:\n",
    "    trace3 = pm.sampling.jax.sample_blackjax_nuts(draws=10000, tune=1000, chains=10, target_accept=0.95, initvals=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with pm.Model() as model4:\n",
    "    # Priors\n",
    "\n",
    "    p = pm.Beta('p', 1, 1)\n",
    "    alpha_2 = pm.Normal('alpha_2', 0.5, 0.1) \n",
    "    alpha_3 = pm.Normal('alpha_3', 0.25, 0.1) \n",
    "\n",
    "    p_i = 1 - (1 - p)**t1 * (1 - alpha_2 * p)**t2 * (1 - alpha_3 * p)**t3\n",
    "    p_i = pm.Deterministic('p_i', p_i)\n",
    "\n",
    "    # Likelihood\n",
    "    y_true = pm.Bernoulli('y_obs', p=p_i, observed=y)\n",
    "\n",
    "    init = {'p': 0.001}\n",
    "\n",
    "with model4:\n",
    "    trace4 = pm.sampling.jax.sample_blackjax_nuts(draws=10000, tune=1000, chains=10, target_accept=0.95, initvals=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples1 = trace1.posterior.stack(sample=(\"chain\", \"draw\"))\n",
    "samples2 = trace2.posterior.stack(sample=(\"chain\", \"draw\"))\n",
    "samples3 = trace3.posterior.stack(sample=(\"chain\", \"draw\"))\n",
    "samples4 = trace4.posterior.stack(sample=(\"chain\", \"draw\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ind1 = pd.DataFrame(samples1['p_i'].values)\n",
    "p_ind2 = pd.DataFrame(samples2['p_i'].values)\n",
    "p_ind3 = pd.DataFrame(samples3['p_i'].values)\n",
    "p_ind4 = pd.DataFrame(samples4['p_i'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace1, round_to=4, hdi_prob=.95);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace2, round_to=4, hdi_prob=.95);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace3, round_to=4, hdi_prob=.95);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace4, round_to=4, hdi_prob=.95);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_model1 = plot_mean_roc(y, p_ind1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_model2 = plot_mean_roc(y, p_ind2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_model3 = plot_mean_roc(y, p_ind3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_model4 = plot_mean_roc(y, p_ind4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_model1 = calculate_mean_confusion_matrix(y, p_ind1, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_model2 = calculate_mean_confusion_matrix(y, p_ind2, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_model3 = calculate_mean_confusion_matrix(y, p_ind3, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_model4 = calculate_mean_confusion_matrix(y, p_ind4, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison: AIC & BIC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='100000' class='' max='100000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [100000/100000 00:05&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC: 8.923047372443115\n",
      "BIC: 17.5585797058818\n",
      "WAIC: Computed from 100000 posterior samples and 64 observations log-likelihood matrix.\n",
      "\n",
      "          Estimate       SE\n",
      "elpd_waic   -30.08     3.81\n",
      "p_waic        1.05        -\n"
     ]
    }
   ],
   "source": [
    "results = calculate_information_criteria(trace1, model1, y)\n",
    "\n",
    "print(f\"AIC: {results['AIC']}\")\n",
    "print(f\"BIC: {results['BIC']}\")\n",
    "print(f\"WAIC: {results['WAIC']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05706067225471734, 0.9437639163435436)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples1 = trace1.posterior.stack(sample=(\"chain\", \"draw\"))\n",
    "\n",
    "alpha1_samples1 = samples1['alpha_1'].values\n",
    "\n",
    "min(alpha1_samples1), max(alpha1_samples1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_model1, bic_model1 = calculate_aic_bic(trace1, model1, y)\n",
    "print(f'AIC for model 1 (all features): {aic_model1}')\n",
    "print(f'BIC for model 1 (all features): {bic_model1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_model2, bic_model2 = calculate_aic_bic(trace2, model2, y)\n",
    "print(f'AIC for model 2 : {aic_model2}')\n",
    "print(f'BIC for model 2 : {bic_model2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_model3, bic_model3 = calculate_aic_bic(trace3, model3, y)\n",
    "print(f'AIC for model 3 : {aic_model3}')\n",
    "print(f'BIC for model 3 : {bic_model3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_model4, bic_model4 = calculate_aic_bic(trace4, model4, y)\n",
    "print(f'AIC for model 4 : {aic_model4}')\n",
    "print(f'BIC for model 4 : {bic_model4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison: Widely Applicable Information Criterion (WAIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = trace1.log_likelihood\n",
    "print(log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_data = trace1['log_likelihood']\n",
    "print(np.isnan(log_likelihood_data).sum())\n",
    "print(np.isinf(log_likelihood_data).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.isinf(log_likelihood_data).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.isnan(log_likelihood_data).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_indices = np.isinf(log_likelihood_data['y_obs']).values\n",
    "print(\"Indices des valeurs infinies :\", np.where(inf_indices)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic1 = az.waic(trace1, model1)\n",
    "waic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic2 = pm.stats.waic(trace2, model2)\n",
    "waic2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic3 = pm.waic(trace3, model3)\n",
    "waic3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic4 = pm.stats.waic(trace4, model4)\n",
    "waic4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison: Pareto-smoothed importance sampling leave-one-out cross-validation (PSIS-LOO-CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"model1\": trace1,\n",
    "    \"model2\": trace2,\n",
    "    \"model3\": trace3,\n",
    "    \"model4\": trace4,\n",
    "}\n",
    "model_compare_default = az.compare(models)\n",
    "model_compare_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_compare(model_compare_default, insample_dev=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compare_waic = az.compare(models, ic='waic', method='BB-pseudo-BMA', b_samples=1000)\n",
    "model_compare_waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compare_loo = az.compare(models, ic='loo', method='BB-pseudo-BMA', b_samples=1000)\n",
    "model_compare_loo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report: F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_model1 = calculate_mean_f1(y, p_ind1, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_model2 = calculate_mean_f1(y, p_ind2, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_model3 = calculate_mean_f1(y, p_ind3, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_model4 = calculate_mean_f1(y, p_ind4, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models' traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trace_model1.pkl', 'wb') as f:\n",
    "    pickle.dump(trace1, f)\n",
    "\n",
    "with open('trace_model2.pkl', 'wb') as f:\n",
    "    pickle.dump(trace2, f)\n",
    "\n",
    "with open('trace_model3.pkl', 'wb') as f:\n",
    "    pickle.dump(trace3, f)\n",
    "\n",
    "with open('trace_model4.pkl', 'wb') as f:\n",
    "    pickle.dump(trace4, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
